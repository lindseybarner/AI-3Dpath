{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reflected-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import h5py\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import tifffile\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from skimage.draw import polygon as ski_polygon\n",
    "import json\n",
    "\n",
    "import openslide\n",
    "from preprocessing.datamodel import SlideManager\n",
    "from preprocessing.processing import split_negative_slide, split_positive_slide, create_tumor_mask, rgb2gray\n",
    "from preprocessing.util import TileMap\n",
    "\n",
    "import calculate_performance as calc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "encouraging-quick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.6.0\n",
      "Torchvision Version:  0.7.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.special import softmax #e to the x and divide by sum\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import date\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "shaped-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "musical-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_show(image, mymax, nrows=1, ncols=1, cmap='gray',size = 8):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(size, size*image.shape[0]/image.shape[1]))\n",
    "    try:\n",
    "        mymax\n",
    "        ax.imshow(image, vmax = mymax, cmap='gray')\n",
    "    except NameError:\n",
    "        ax.imshow(image, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confidential-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_test_case_patches(path, test_case):  \n",
    "    if os.path.exists(path + '//test//') == False:\n",
    "        os.mkdir(path + '//test//')\n",
    "        \n",
    "    # Make folder to move all test patches to\n",
    "    if os.path.exists(path + '//test//' + str(test_case)) == False:\n",
    "        os.mkdir(path + '//test//' + str(test_case) + '//')\n",
    "        os.mkdir(path + '//test//' + str(test_case) + '//0//')\n",
    "        os.mkdir(path + '//test//' + str(test_case) + '//1//')\n",
    "    print('created patch-based test folder in path: ' + str(path) + '//test//' + str(test_case) + '//')\n",
    "\n",
    "    ## Copy test case 0 patches to the new folder\n",
    "    for file in os.listdir(path + '//all//0//'):\n",
    "        if file.startswith(test_case):\n",
    "            source = path + '//all//0//' + file\n",
    "            dest = path + '//test//' + str(test_case) + '//0//' + file\n",
    "            shutil.copy(source, dest) #move to designated path\n",
    "\n",
    "    ## Copy test case 1 patches to the new folder\n",
    "    for file in os.listdir(path + '//all//1//'):\n",
    "        if file.startswith(test_case):\n",
    "            source = path + '//all//1//' + file\n",
    "            dest = path + '//test//' + str(test_case) + '//1//' + file\n",
    "            shutil.copy(source, dest) #move to designated path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "arbitrary-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = ''\n",
    "\n",
    "mgr = SlideManager(cam16_dir=DIR)\n",
    "\n",
    "slides_met = mgr.met_slides\n",
    "\n",
    "N_met = len(slides_met)\n",
    "\n",
    "slides_negative = mgr.negative_slides\n",
    "\n",
    "N_negative = len(slides_negative)\n",
    "\n",
    "level = 0\n",
    "\n",
    "tile_size = 512 #must be the same as used for training\n",
    "\n",
    "poi = 0.50 #must use the same poi we used to seperate tisse from background\n",
    "\n",
    "overlap = tile_size // 2 #increasing overlap will put patches closer together\n",
    "\n",
    "input_size = tile_size\n",
    "\n",
    "n_folds = 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worldwide-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \".//patches//test//\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-barrel",
   "metadata": {},
   "source": [
    "## Test all models, save all ROC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "overhead-intermediate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for 08159A1-a\n",
      "Model name = resnet_Kfold_0_('08159A1-a', '7115B-a').pt\n",
      "Making predictions for 7115B-a\n",
      "Model name = resnet_Kfold_0_('08159A1-a', '7115B-a').pt\n"
     ]
    }
   ],
   "source": [
    "prediction_folder_path = 'predictions//Kfold//'\n",
    "patches_path = 'patches//'\n",
    "auc_all = []\n",
    "for fold in range(n_folds):\n",
    "    for file in os.listdir():\n",
    "        if file.startswith('resnet_Kfold_' + str(fold) + '_') and file.endswith('.pt'): ##\n",
    "            \n",
    "            ## Define test cases for this model\n",
    "            test_case = []\n",
    "            cases = file.split('(')[1].split(')')[0] ## Grab names of cases for this model. Format 'case', 'case' \n",
    "            test_case.append(cases.split(',')[0][1:-1]) ## Grab first case. Cut off ' ' at the beg/end of name\n",
    "            test_case.append(cases.split(',')[1][2:-1]) ## Grab second case. Cut off space at beg, and ' ' at the beg/end of name \n",
    "\n",
    "            ## Load model\n",
    "            model_name = file\n",
    "            model = torch.load(model_name)\n",
    "            model.eval()\n",
    "\n",
    "            try:\n",
    "                all_outputs\n",
    "                del all_outputs\n",
    "            except NameError:\n",
    "                print('initializing variables')\n",
    "            try:\n",
    "                all_labels\n",
    "                del all_labels\n",
    "            except NameError:\n",
    "                pass\n",
    "\n",
    "            for ii in range(len(test_case)):                      \n",
    "                dataset_name = test_case[ii]\n",
    "                \n",
    "                if os.path.exists(patches_path + '//test//' + str(test_case[ii])) == False: ## If test patches do NOT exist,\n",
    "                    copy_test_case_patches(patches_path, dataset_name) ## then copy test patches to folder\n",
    "                    print('copying test patches for ' + str(dataset_name))\n",
    "                \n",
    "                print('Making predictions for ' + str(dataset_name))\n",
    "                print('Model name = ' + str(model_name))\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                n_classes = 2\n",
    "\n",
    "                data_transforms = {\n",
    "                dataset_name: transforms.Compose([\n",
    "                transforms.Resize(input_size),\n",
    "                transforms.CenterCrop(input_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "\n",
    "                # Create dataloader\n",
    "                image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in [dataset_name]}\n",
    "                dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in [dataset_name]}\n",
    "\n",
    "                # Detect if we have a GPU available\n",
    "                device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "                running_corrects = 0\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders_dict[dataset_name]: #get inputs. data is list of [inputs, labels]\n",
    "                    out = torchvision.utils.make_grid(inputs) #for visualizing inputs\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(inputs) #output is not normalized\n",
    "                    #criterion function normalizes the outputs into probabilities with softmax\n",
    "                    loss = criterion(outputs, labels) #loss being nn.CrossEntropy\n",
    "                    _, preds = torch.max(outputs, 1) #prediction is given to maximum probability. i.e. threshold = 0.50\n",
    "\n",
    "                    labels_cpu = labels.cpu().detach().numpy()\n",
    "                    preds_cpu = preds.cpu().detach().numpy()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data) #Number of corrects in each batch\n",
    "\n",
    "                    ## Store ALL labels and outputs for plot\n",
    "                    try:\n",
    "                        all_outputs\n",
    "                        all_outputs = np.append(all_outputs, outputs.cpu().detach().numpy(), axis = 0) \n",
    "                        all_labels = np.append(all_labels, labels.cpu().detach().numpy(), axis = 0)\n",
    "                    except NameError:\n",
    "                        all_outputs = outputs.cpu().detach().numpy() #initial element of all_outputs\n",
    "                        all_labels = labels.cpu().detach().numpy() #initial element of all_outputs\n",
    "\n",
    "            ## Get ROC curve for both test cases from this model\n",
    "            fpr = dict()\n",
    "            tpr = dict()\n",
    "            roc_auc = dict()\n",
    "            outputs_normalized = softmax(all_outputs, axis = 1)\n",
    "\n",
    "            #create y_score (matrix of labels, 2 columns, 1 in column for positive class)\n",
    "            y_score = np.zeros((len(all_labels),2))\n",
    "            for col in range(len(all_labels)):\n",
    "                y_score[col,all_labels[col]] = 1 #if labels_cpu[col] is 1, col 1 = 1\n",
    "            for i in range(2):\n",
    "                fpr[i], tpr[i], _ = roc_curve(y_score[:,i], outputs_normalized[:,i])\n",
    "                roc_auc[i] = auc(fpr[i],tpr[i])\n",
    "                \n",
    "            ## Save records of this test \n",
    "            np.save(prediction_folder_path + '//ROC//' + str(fold) + '_fpr.npy', fpr[1])\n",
    "            np.save(prediction_folder_path + '//ROC//' + str(fold) + '_tpr.npy', tpr[1])\n",
    "            np.save(prediction_folder_path + '//ROC//outputs_labels//' + str(fold) + '_all_labels.npy', all_labels)\n",
    "            np.save(prediction_folder_path + '//ROC//outputs_labels//' + str(fold) + '_all_outputs.npy', all_outputs)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
