{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "special-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.6.0\n",
      "Torchvision Version:  0.7.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import h5py\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import tifffile\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from skimage.draw import polygon as ski_polygon\n",
    "import json\n",
    "import calculate_performance as calc\n",
    "\n",
    "import openslide\n",
    "from preprocessing.datamodel import SlideManager\n",
    "from preprocessing.processing import split_negative_slide, split_positive_slide, create_tumor_mask, rgb2gray\n",
    "from preprocessing.util import TileMap\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.special import softmax #e to the x and divide by sum\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offensive-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "binary-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_show(image, mymax, nrows=1, ncols=1, cmap='gray',size = 8):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(size, size*image.shape[0]/image.shape[1]))\n",
    "    try:\n",
    "        mymax\n",
    "        ax.imshow(image, vmax = mymax, cmap='gray')\n",
    "    except NameError:\n",
    "        ax.imshow(image, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "explicit-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = ''\n",
    "\n",
    "mgr = SlideManager(cam16_dir=DIR)\n",
    "\n",
    "slides_met = mgr.met_slides\n",
    "\n",
    "N_met = len(slides_met)\n",
    "\n",
    "slides_negative = mgr.negative_slides\n",
    "\n",
    "N_negative = len(slides_negative)\n",
    "\n",
    "level = 0\n",
    "\n",
    "tile_size = 512 #must be the same as used for training\n",
    "\n",
    "poi = 0.50 #must use the same poi we used to seperate tisse from background\n",
    "\n",
    "overlap = tile_size // 2 #increasing overlap will put patches closer together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "middle-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"test//\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "prediction_folder_path = 'predictions//'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-dividend",
   "metadata": {},
   "source": [
    "## Generate heatmaps for OTLS en face images (\"slides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "colonial-closer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for case00\n",
      "Model name = fold00_model.pt\n",
      "Making predictions for case00\n",
      "Model name = fold00_model.pt\n"
     ]
    }
   ],
   "source": [
    "## Go through each slide, find corresponding trained model, and generate heatmap\n",
    "for i in range(len(mgr.slides)):\n",
    "    slide = mgr.slides[i] ## Define which slide to generate predictions on \n",
    "    case_name = slide.name.split('_')[0] ## Grab case name from file name - relies on provided naming convention format\n",
    "    case_number = case_name[-2:] ## Conver the last two digits to integer\n",
    "\n",
    "    model_name = 'fold' + str(case_number) + '_model.pt'\n",
    "    model = torch.load(model_name)\n",
    "    model.eval()\n",
    "    print('Making predictions for ' + str(case_name))\n",
    "    print('Model name = ' + str(model_name))\n",
    "\n",
    "    input_size = 512 # Define patch size in pixels \n",
    "    \n",
    "    ## Compute threshold we will use to define tissue regions using Otsu\n",
    "    arr = np.asarray(slide.get_full_slide(level=4))\n",
    "    arr_gray = rgb2gray(arr)\n",
    "    threshold = threshold_otsu(arr_gray)\n",
    "    \n",
    "    # Get ground truth label (2D mask)\n",
    "    mask = create_tumor_mask(slide, level=level)\n",
    "\n",
    "    # #Initialize heatmap\n",
    "    slide_level0 =  np.asarray(slide.get_full_slide(level = 0))[:,:,:3]\n",
    "    size = slide.level_dimensions[level]\n",
    "\n",
    "    # Load patch/tile iterator\n",
    "    tile_iter = split_negative_slide(\n",
    "        slide, level=level,\n",
    "        otsu_threshold=threshold,  # otsu threshold calculated earlier\n",
    "        tile_size=tile_size,\n",
    "        overlap=overlap,                 # overlap between patches\n",
    "        poi_threshold=poi,\n",
    "        verbose = False)         # only select tiles with at least 5% tissue\n",
    "\n",
    "    ## Initialize variables     \n",
    "    all_outputs_normalized = None ## Will be a 2D array of all patch-based predictions (column 0 = P(0), column 1 = P(1))\n",
    "    Ptumor = None\n",
    "    P = None ## Probability that a single patch is neoplastic\n",
    "    all_labels = None\n",
    "\n",
    "    heatmap_fullres = np.zeros((size[1] + tile_size, size[0] + tile_size), dtype = 'float64') # Initialize heatmap array\n",
    "    division_map = np.zeros((size[1] + tile_size, size[0] + tile_size),dtype = 'float64') # Initialize map that will help us account for duplicate predictions\n",
    "    \n",
    "    ii = 0\n",
    "    for patch, bounds in tile_iter: #bounds is (X,Y),(width,height)\n",
    "        ## Get coordinates of patch on full res slide\n",
    "        #Assumes start_pos = (0,0)\n",
    "        X = bounds[0][0] #X coordinate of top left corner on full-resolution slide (not downsampled by level)\n",
    "        Y = bounds[0][1] #Y coordinate of top left corner on full-resolution slide\n",
    "        width = bounds[1][0] #width of patch\n",
    "        height = bounds[1][1] #height of patch\n",
    "\n",
    "        ## Perform same preprocessing that is done on patches\n",
    "        patch = patch.astype('float64')\n",
    "        patch[:,:,0] = patch[:,:,0]*255/patch[:,:,0].max()\n",
    "        patch[:,:,1] = patch[:,:,1]*255/patch[:,:,1].max()\n",
    "\n",
    "        #Format patch and predict probability of having neoplasia\n",
    "        patch = np.moveaxis(patch, 2, 0)\n",
    "        patch = np.expand_dims(patch,0)\n",
    "        patch = np.float32(patch) #tensors loaded by dataloader are float32\n",
    "        patch[:,0,:,:] = patch[:,0,:,:]/patch[:,0,:,:].max() # Normalize channel 0 to its max\n",
    "        patch[:,1,:,:] = patch[:,1,:,:]/patch[:,1,:,:].max() # Normalize channel 1 to its max\n",
    "\n",
    "        #Perform same operation as transforms. Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        patch[:,0,:,:] = (patch[:,0,:,:] - .485)/.229\n",
    "        patch[:,1,:,:] = (patch[:,1,:,:] - .456)/.224\n",
    "        patch[:,2,:,:] = (patch[:,2,:,:] - .406)/.225\n",
    "\n",
    "        patch = torch.from_numpy(patch)\n",
    "        patch = patch.to(device)\n",
    "        output = model(patch)\n",
    "        output_normalized = softmax(output.cpu().detach().numpy(),axis = 1) #array of size (2,1)\n",
    "        P = output_normalized[0][1] #extracts JUST the probability for class 1\n",
    "\n",
    "        ##GROUND TRUTH\n",
    "        ## Get coordinates of patch on slide downsampled by level\n",
    "        r = np.array((Y, Y, Y+height, Y+height), dtype=np.float32)\n",
    "        r /= round(slide.level_downsamples[level]) # will != 1 if downsampling is applied\n",
    "        r = np.array(r + 0.5, dtype=np.int32) # converts to integer (rounds decimals down)\n",
    "        c = np.array((X, X+width, X+width, X), dtype=np.float32)\n",
    "        c /= round(slide.level_downsamples[level]) #will != 1 if downsampling is applied\n",
    "        c = np.array(c + 0.5, dtype=np.int32) # converts to integer (rounds decimals down)\n",
    "        rr, cc = ski_polygon(r, c, shape=mask.shape) ##patch coords of TISSUE\n",
    "\n",
    "        ## Assign heatmap values \n",
    "        heatmap_fullres[r[0]:r[3], c[0]:c[1]] += P\n",
    "        division_map[r[0]:r[3], c[0]:c[1]] += 1 ## Keep track of how many times we have predicted on this patch (and added to the heatmap)\n",
    "\n",
    "        ## Get ground truth label according to mask (downsampled by level)\n",
    "        if mask[rr,cc].max() == 1:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "        if all_outputs_normalized is None:\n",
    "            all_outputs_normalized = output_normalized\n",
    "            all_labels = label\n",
    "            Ptumor = P\n",
    "        else:\n",
    "            all_outputs_normalized = np.append(all_outputs_normalized, output_normalized, axis = 0)\n",
    "            all_labels = np.append(all_labels, label)\n",
    "            Ptumor = np.append(Ptumor, P)    \n",
    "\n",
    "        ii += 1\n",
    "\n",
    "    ## Divide the heatmap by the division map so that all pixels represent the average of all predictions made on each patch\n",
    "    division_map[np.where(division_map == 0)] = 1\n",
    "    heatmap_fullres = heatmap_fullres/division_map\n",
    "\n",
    "    ## Save the ground truth mask\n",
    "    slide_mask = np.zeros((size[1], size[0]), dtype = 'uint8')\n",
    "    r, c = np.where(mask == 1)\n",
    "    slide_mask[r,c] = 255  #For solid red overlay: slide_mask[r,c,0] = 255 # slide_mask[r,c,1:] = 0\n",
    "    tifffile.imwrite(prediction_folder_path + str(slide.name) + '_ground truth.tiff', slide_mask, photometric = 'rgb')\n",
    "\n",
    "    ## Save heatmap. Full res version as float64 (cannot open in FIJI), and downsampled version as float32 (can visualize in FIJI)\n",
    "    tifffile.imwrite(prediction_folder_path + str(slide.name)+ '_heatmap.tiff', heatmap_fullres.astype('float64'), photometric = 'minisblack')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_6",
   "language": "python",
   "name": "python3_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
