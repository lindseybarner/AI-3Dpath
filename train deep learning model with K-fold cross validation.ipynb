{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protected-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import h5py\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "import tifffile\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import copy\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import openslide\n",
    "from preprocessing.datamodel import SlideManager\n",
    "from preprocessing.processing import split_negative_slide, split_positive_slide, create_tumor_mask, rgb2gray\n",
    "from preprocessing.util import TileMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4a820",
   "metadata": {},
   "source": [
    "## Functions to shuffle test patches out of training folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bb1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_test_case_patches(patches_dir, test_case):  \n",
    "    \n",
    "    # Make folder to move all test patches to. Model will not see this during training\n",
    "    if os.path.exists('patches//test_patches') == False:\n",
    "        os.mkdir(patches_dir + '//test_patches//')\n",
    "        os.mkdir(patches_dir + '//test_patches//0//')\n",
    "        os.mkdir(patches_dir + '//test_patches//1//')\n",
    "    print('created folder for ' + str(test_case) + (' test patches'))\n",
    "\n",
    "    ## Move test case 0 patches to the new folder\n",
    "    for file in os.listdir(patches_dir + '//train_patches//0//'):\n",
    "        if file.startswith(test_case):\n",
    "            source = patches_dir + '//train_patches//0//' + file\n",
    "            dest = patches_dir + '//test_patches//0//' + file\n",
    "            shutil.move(source, dest) #move to designated path\n",
    "\n",
    "    ## Move test case 1 patches to the new folder\n",
    "    for file in os.listdir(patches_dir + '//train_patches//1//'):\n",
    "        if file.startswith(test_case):\n",
    "            source = patches_dir + '//train_patches//1//' + file\n",
    "            dest = patches_dir + '//test_patches//1//' + file\n",
    "            shutil.move(source, dest) #move to designated path\n",
    "\n",
    "    print('files for test case ' + str(test_case) + ' all moved, ready to train')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imperial-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_patches(patches_dir, test_case):\n",
    "    ## Move files back to patches//all folder\n",
    "    for file in os.listdir(patches_dir + '//test_patches//0//'):\n",
    "        if file.startswith(test_case):\n",
    "            source = patches_dir + '//test_patches//0//' + file\n",
    "            dest = patches_dir + '//train_patches//0//' + file\n",
    "            shutil.move(source, dest) #move to designated path\n",
    "\n",
    "    for file in os.listdir(patches_dir + 'test_patches//1//'):\n",
    "        if file.startswith(test_case):\n",
    "            source = patches_dir + '//test_patches//1//' + file\n",
    "            dest = patches_dir + '//train_patches//1//' + file\n",
    "            shutil.move(source, dest) #move to designated path\n",
    "            \n",
    "    ## Make sure test case folder is empty before deleting directory\n",
    "    if len(os.listdir(patches_dir + 'test_patches//0//')) == 0 and len(os.listdir(patches_dir + 'test_patches//1//')) == 0:\n",
    "        print('deleting directory test_patches//')\n",
    "        os.rmdir(data_dir + 'test_patches//0')\n",
    "        os.rmdir(data_dir +'test_patches//1')\n",
    "        os.rmdir(data_dir +'test_patches')\n",
    "    else:\n",
    "        print('test patch directory is not empty, not deleting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bff9cf",
   "metadata": {},
   "source": [
    "## Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fallen-mumbai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated slides: 2\n",
      "Number of normal slides: 2\n"
     ]
    }
   ],
   "source": [
    "## Define parameters\n",
    "# Define directory and slide manager\n",
    "DIR = ''\n",
    "mgr = SlideManager(cam16_dir=DIR)\n",
    "\n",
    "# Get annotated slides\n",
    "slides_met = mgr.met_slides\n",
    "N_met = len(slides_met)\n",
    "print('Number of annotated slides:', N_met)\n",
    "\n",
    "# Get normal slides\n",
    "slides_negative = mgr.negative_slides\n",
    "N_negative = len(slides_negative)\n",
    "print('Number of normal slides:', N_negative)\n",
    "\n",
    "data_dir = 'patches//'\n",
    "\n",
    "model_name = \"resnet\" #\"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "input_size = 512\n",
    "\n",
    "# Number of epchs to train for\n",
    "num_epochs = 20\n",
    "\n",
    "feature_extract = False\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "valuable-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model function handles training and validation of a given model\n",
    "#inputs: PyTorch model, dictionary of dataloaders, loss function, optimizer,\n",
    "#number of epochs to train/validate for\n",
    "#during training, it keeps track of best performing model in terms of validation\n",
    "#accuracy. at the end, it returns the best performing model\n",
    "\n",
    "def train_model(model, fold, dataloaders_train, criterion, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "    phase = 'train'\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Each epoch has a training and validation phase\n",
    "        ## Initialize variables\n",
    "        all_labels = None\n",
    "        all_outputs = None\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "        model.train()  # Set model to training mode\n",
    "        dataloaders = dataloaders_train['train_patches']\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        ii = 0\n",
    "        for inputs, labels in dataloaders: #get inputs. data is list of [inputs, labels]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                # Get model outputs and calculate loss\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                positive_predictions = np.where(preds.cpu().detach().numpy() == 1)\n",
    "                negative_predictions = np.where(preds.cpu().detach().numpy() == 0)\n",
    "\n",
    "                labels_cpu = labels.cpu().detach().numpy()\n",
    "                preds_cpu = preds.cpu().detach().numpy()\n",
    "                N_preds = len(labels_cpu)\n",
    "                N_1 = sum(labels_cpu)\n",
    "                N_0 = N_preds - N_1\n",
    "                N_correct = len(np.where(labels_cpu == preds_cpu)[0])\n",
    "\n",
    "                if all_outputs is None:\n",
    "                    all_outputs = outputs.cpu().detach().numpy()\n",
    "                    all_labels = labels_cpu\n",
    "                else:\n",
    "                    all_outputs = np.append(all_outputs, outputs.cpu().detach().numpy(), axis = 0)\n",
    "                    all_labels = np.append(all_labels, labels_cpu)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            ii += 1\n",
    "\n",
    "        epoch_loss = running_loss / (ii*batch_size) #len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_corrects.double() / (ii*batch_size) #len(dataloaders[phase].dataset)\n",
    "        train_loss_history.append(epoch_loss)\n",
    "        \n",
    "        ## Save models across all epochs\n",
    "#         torch.save(model, 'model for fold ' + str(fold) + ', epoch ' + str(epoch) + '.pt') \n",
    "        print('epoch loss = ' + str(epoch_loss))\n",
    "\n",
    "    plt.figure\n",
    "    plt.plot(train_loss_history,'b')\n",
    "    plt.show()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model, train_loss_history, all_outputs, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "diverse-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When feature extracting, we only want to update parameters of last layer\n",
    "# Therefore, do not need to compute gradients for the rest of model\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "endless-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        ## Add dropout layer\n",
    "        model_ft.fc = nn.Sequential(nn.Dropout(0.5),nn.Linear(num_ftrs, 2))\n",
    "        input_size = 512 #256# 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 256 #224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 256 #224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Print the model we just instantiated\n",
    "# print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "occupational-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patches in metaplasia-negative training set: 244\n",
      "Number of patches in metaplasia-positive training set: 181\n"
     ]
    }
   ],
   "source": [
    "#Find number of files in train//0//\n",
    "path = data_dir + '//train_patches//0//'\n",
    "N_0 = 0\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.tif'):\n",
    "        N_0 += 1\n",
    "\n",
    "print('Number of patches in metaplasia-negative training set: ' + str(N_0))\n",
    "\n",
    "#Find number of files in train//1//\n",
    "N_1 = 0\n",
    "path = data_dir + '//train_patches//1//'\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.tif'):\n",
    "        N_1 += 1\n",
    "print('Number of patches in metaplasia-positive training set: ' + str(N_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-housing",
   "metadata": {},
   "source": [
    "## Identify cases and set up transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "representative-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = data_dir + '//train_patches//'\n",
    "\n",
    "## Get list of case names and class (0 or 1) for all patches\n",
    "cases = []\n",
    "\n",
    "dataset = datasets.ImageFolder(root = path)\n",
    "for i in range(len(dataset.imgs)):\n",
    "    patch_name = dataset.imgs[i][0].split('\\\\') ## Grab file name of the patch\n",
    "    patch_case = patch_name[1].split('_')[0] ## Grab case name from file name - relies on \"case##_\" format\n",
    "\n",
    "    if patch_case not in cases:\n",
    "        cases.append(patch_case)\n",
    "\n",
    "N_cases = len(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "urban-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train_patches': transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=(0, 180)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.ColorJitter(hue = 0.25),\n",
    "        transforms.ColorJitter(brightness = 0.4),\n",
    "        transforms.ColorJitter(contrast = 0.40),\n",
    "        transforms.ColorJitter(saturation = 0.10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-vietnam",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unexpected-claim",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test case is case00\n",
      "created folder for case00 test patches\n",
      "files for test case case00 all moved, ready to train\n",
      "N_0 = 110\n",
      "N_1 = 70\n",
      "test case = case00\n",
      "dataloaders_train = {'train_patches': <torch.utils.data.dataloader.DataLoader object at 0x000001DF8C09DA20>}\n",
      "Epoch 0/19\n",
      "epoch loss = 0.7797203709681829\n",
      "Epoch 1/19\n",
      "epoch loss = 0.6385753800471624\n",
      "Epoch 2/19\n",
      "epoch loss = 0.4930993740757306\n",
      "Epoch 3/19\n",
      "epoch loss = 0.3975772752116124\n",
      "Epoch 4/19\n",
      "epoch loss = 0.3854825732608636\n",
      "Epoch 5/19\n",
      "epoch loss = 0.33164975481728715\n",
      "Epoch 6/19\n",
      "epoch loss = 0.27949355728924274\n",
      "Epoch 7/19\n",
      "epoch loss = 0.2386741548155745\n",
      "Epoch 8/19\n",
      "epoch loss = 0.21900592744350433\n",
      "Epoch 9/19\n",
      "epoch loss = 0.20999584533274174\n",
      "Epoch 10/19\n",
      "epoch loss = 0.22220958955585957\n",
      "Epoch 11/19\n",
      "epoch loss = 0.13023654526720443\n",
      "Epoch 12/19\n",
      "epoch loss = 0.1341610069697102\n",
      "Epoch 13/19\n",
      "epoch loss = 0.1077622314915061\n",
      "Epoch 14/19\n",
      "epoch loss = 0.1643722246711453\n",
      "Epoch 15/19\n",
      "epoch loss = 0.14621113644291958\n",
      "Epoch 16/19\n",
      "epoch loss = 0.09567558113485575\n",
      "Epoch 17/19\n",
      "epoch loss = 0.10006673913449049\n",
      "Epoch 18/19\n",
      "epoch loss = 0.07305771516015132\n",
      "Epoch 19/19\n",
      "epoch loss = 0.06415173970162868\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 4m 4s\n",
      "GPU memory used = 11.572150784\n",
      "deleting directory test_patches//\n",
      "image patch locations have been reset\n",
      "\n",
      "test case is case01\n",
      "created folder for case01 test patches\n",
      "files for test case case01 all moved, ready to train\n",
      "N_0 = 134\n",
      "N_1 = 111\n",
      "test case = case01\n",
      "dataloaders_train = {'train_patches': <torch.utils.data.dataloader.DataLoader object at 0x000001DF8D68C780>}\n",
      "Epoch 0/19\n",
      "epoch loss = 0.7052892874926329\n",
      "Epoch 1/19\n",
      "epoch loss = 0.642664851155132\n",
      "Epoch 2/19\n",
      "epoch loss = 0.5885129522066563\n",
      "Epoch 3/19\n",
      "epoch loss = 0.4829393606632948\n",
      "Epoch 4/19\n",
      "epoch loss = 0.4198697723913938\n",
      "Epoch 5/19\n",
      "epoch loss = 0.388317282195203\n",
      "Epoch 6/19\n",
      "epoch loss = 0.3567520307842642\n",
      "Epoch 7/19\n",
      "epoch loss = 0.43376960896421224\n",
      "Epoch 8/19\n",
      "epoch loss = 0.34454586647916585\n",
      "Epoch 9/19\n",
      "epoch loss = 0.3069106239126995\n",
      "Epoch 10/19\n",
      "epoch loss = 0.30206949345301837\n",
      "Epoch 11/19\n",
      "epoch loss = 0.3215226230677217\n",
      "Epoch 12/19\n",
      "epoch loss = 0.30811946536414325\n",
      "Epoch 13/19\n",
      "epoch loss = 0.23863690625876188\n",
      "Epoch 14/19\n",
      "epoch loss = 0.29873883817344904\n",
      "Epoch 15/19\n",
      "epoch loss = 0.2551503765862435\n",
      "Epoch 16/19\n",
      "epoch loss = 0.2666068768594414\n",
      "Epoch 17/19\n",
      "epoch loss = 0.2440260985167697\n",
      "Epoch 18/19\n",
      "epoch loss = 0.2577562965452671\n",
      "Epoch 19/19\n",
      "epoch loss = 0.20819008257240057\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 4m 42s\n",
      "GPU memory used = 12.10797312\n",
      "deleting directory test_patches//\n",
      "image patch locations have been reset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "for test_case in cases:\n",
    "    print('test case is ' + str(test_case))\n",
    "\n",
    "    ### Move patches that correspond to testing case to a new folder (these patches will not be used for training)\n",
    "    move_test_case_patches(data_dir, test_case)\n",
    "\n",
    "    # Initialize the model for this run\n",
    "    model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "    ## Create optimizer\n",
    "    model_ft = model_ft.to(device) ## Send model to GPU\n",
    "    params_to_update = model_ft.parameters()\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "    else:\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                pass\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "    ## Get training ID's for this particular fold\n",
    "    train_idx = []\n",
    "    train_class = []\n",
    "    train_case_0 = []\n",
    "    train_case_1 = []\n",
    "\n",
    "    ## All patches within this loop are train patches\n",
    "    train_dataset = datasets.ImageFolder(root = 'patches//train_patches//')\n",
    "\n",
    "    for i in range(len(train_dataset.imgs)): #Go through all dataset patches\n",
    "        patch_name = train_dataset.imgs[i][0].split('\\\\') ## Grab file name of the patch\n",
    "        patch_case = patch_name[1].split('_')[0] ## Grab case name from file name - relies on \"case_\" format\n",
    "        patch_class = train_dataset.imgs[i][1] ## Grab class of the patch (0 or 1)\n",
    "\n",
    "        ## If patch is within training dataset (i.e. not from testing case)\n",
    "        if patch_case not in test_case:\n",
    "            train_idx.append(i)\n",
    "            train_class.append(patch_class)\n",
    "            if patch_class == 0:\n",
    "                train_case_0.append(patch_case) #Append the case to list of negative training patches\n",
    "            if patch_class == 1:\n",
    "                train_case_1.append(patch_case) #Append the case to list of negative training patches\n",
    "\n",
    "        ## If specific patch belongs to case we are testing on, then a patch has not been correctly moved to test folder\n",
    "        if patch_case in test_case:\n",
    "            print('ERROR - check that test patches are not in training folder')\n",
    "\n",
    "    ## Count how many patches correspond to each case for 0 and 1. Depends on case names being unique in the list (check this manually)\n",
    "    counts_0 = Counter(train_case_0) \n",
    "    counts_1 = Counter(train_case_1)\n",
    "\n",
    "    N_0 = len(train_case_0) #Number of zero patches in training cases\n",
    "    N_1 = len(train_case_1 )#Number of one patches in training cases \n",
    "    print('N_0 = ' + str(N_0))\n",
    "    print('N_1 = ' + str(N_1))\n",
    "\n",
    "    ## Create weighted sampler for patches\n",
    "    ## During training, positive patches will be loaded just as frequently as negative patches to avoid bias from imbalanced datasets\n",
    "    weights_train = []\n",
    "    for i in range(len(train_dataset.imgs)):\n",
    "        if i in train_idx:\n",
    "            patch_name = train_dataset.imgs[i][0].split('\\\\') ## Grab file name of the patch\n",
    "            patch_case = patch_name[1].split('_')[0] ## Grab case name from file name - relies on \"case##_\" format\n",
    "            patch_class = train_dataset.imgs[i][1] ## Grab class of the patch (0 or 1)\n",
    "\n",
    "            if patch_class == 0:\n",
    "                weight = (1/counts_0[patch_case])/(N_0+N_1)\n",
    "                weights_train.append(weight)\n",
    "            if patch_class == 1:\n",
    "                weight = 2*(1/counts_1[patch_case])/(N_0+N_1)\n",
    "                weights_train.append(weight)\n",
    "\n",
    "    train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights_train, len(train_dataset), replacement = True)\n",
    "\n",
    "    ## Define dataloaders for downsampled training session\n",
    "#     train_image_datasets = {datasets.ImageFolder(data_dir, data_transforms)}\n",
    "    train_image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train_patches']}\n",
    "    dataloaders_train = {x: torch.utils.data.DataLoader(train_image_datasets[x], batch_size = batch_size, sampler = train_sampler, num_workers=4) for x in ['train_patches']}\n",
    "\n",
    "    print('test case = ' + str(test_case))\n",
    "    print('dataloaders_train = ' + str(dataloaders_train))\n",
    "    \n",
    "    # Train and evaluate\n",
    "    model_ft, train_loss_history, all_outputs, all_labels  = train_model(model_ft, fold, dataloaders_train, criterion, optimizer_ft, num_epochs)\n",
    "    print('GPU memory used = ' + str((torch.cuda.memory_reserved() + torch.cuda.memory_allocated())/(1e9)))\n",
    "\n",
    "    # Save model for this fold\n",
    "    PATH = 'resnet_gitest_' + str(fold) + '_' + str(test_case) + '.pt'\n",
    "    if os.path.isfile(PATH) == True:\n",
    "        print('Model has already been saved to this name. Not over-writing')\n",
    "    else:\n",
    "        torch.save(model_ft, PATH)  \n",
    "\n",
    "    ## Delete variables to clear memory and ensure that learned parameters do not leak between folds\n",
    "    del model_ft, train_loss_history, all_outputs, all_labels, optimizer_ft, params_to_update, \n",
    "\n",
    "    ## Reset all test patches\n",
    "    reset_patches(data_dir, test_case)\n",
    "        \n",
    "    print('image patch locations have been reset')\n",
    "    print('')\n",
    "    torch.cuda.empty_cache()\n",
    "    fold += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
